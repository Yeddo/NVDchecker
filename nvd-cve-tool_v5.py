'''
# ***********************************************************************
# AUTHOR = Jason Bisnette
# VERSION = 5.0
# EMAIL = jason.bisnette@gmail.com
# DESCRIPTION = This script takes a package listing checks each package
# and version on the national vulerability database and creates an excel
# document with the results.
# USAGE = 
        To parse package output for tool to run correctly:
            python nvc-cve-tool_v5.py 
        To run tool with fixed format file:
            python nvd-cve-tool_v5.py -k 9e0a566b-c66d-487b-bc98-0b64773224ff -b "Opkg CVE's for WindRiver Linux 4.19.128" -i fixed_output_file.txt -o cve.xlsx
        To create fixed format file from SWID SBOM:
            python nvd-cve-tool_v5.py -s sbom -f C:\Users\<name>\Desktop\Test\swid\hypervisor-image -o C:\Users\<name>\Desktop\Test\cve\output.txt -k 9e0a566b-c66d-487b-bc98-0b64773224ff
        To run on the file with the output of 'opkg list-installed' command:
            python nvd-cve-tool_v5.py -s sbom -i C:\Users\<name>\Desktop\Test\cve\opkgList.txt -o C:\Users\<name>\Desktop\Test\cve\output.txt -k 9e0a566b-c66d-487b-bc98-0b64773224ff

# FILENAME = nvd-cve-tool_v5.py
# NOTES: 
# CHANGES: Added other OS parsers as a placeholder and auto detect OS
# ***********************************************************************
TODO:
- Fix Package Parser for redhat
- Fix Package Parser for fedora
- Fix Package Parser for windriver
- Fix Auto Detect and parse input file for kernel/OS type
- Fix relative path for input/output files.
'''

# Imports
import requests # GET request
import json     # Json library
import openpyxl # Excel libraries
from openpyxl.workbook import Workbook
from openpyxl.styles import Font
from openpyxl.styles import Alignment
from openpyxl.utils import get_column_letter
import argparse # Parses arguments
import sys      # For slow printing function
import time     # Time to sleep for queries without API key
from progress.bar import IncrementalBar  # Status bar
import re       # For regex
import os       # For path
import urllib.request   # For URL connection
import datetime # For timer
import xml.etree.ElementTree as ET # For SWID parser/XML.
import tqdm

# Set up excel workbook and sheet variables
wb = openpyxl.Workbook()
ws = wb.active

# Function to check internet access.
def connect(host='https://nvd.nist.gov/'):
    try:
        urllib.request.urlopen(host) #Python 3.x
        return True
    except:
        return False

# Function to print text slowly. Fancy!
def delay_print(s):
    for c in s:
        # Two tricks here ...
        sys.stdout.write(c) # 1. you need to use a stream to get everything in the right place.
        sys.stdout.flush() # 2. you also need to flush the stream buffer.
        time.sleep(0.05) # Adjust to speed up/slow down.

# Set up Excel spreadsheet and write header row.
def excelSetup():
    ws.merge_cells('A1:F2')
    cell = ws.cell(row=1, column=1)
    cell.value = bannerInfo
    cell.alignment = Alignment(horizontal='center', vertical='center')
    ws['A1'].font = Font(bold=True, size=18)
    # This moves the row down because for some reason the merge doesn't get seen as 2 rows, only 1 but the next appended row ends up blank if this isn't here. ¯\_(ツ)_/¯
    ws.append([""])
    # This needs to be here before changing font style otherwise it'll "append" below first row. Or you can specify where every cell goes that the column headers go in individually (ws['A1'] = "Package Version").
    ws.append(["Package Name", "Package Version", "CVE ID", "CVSS Score", "Published Date", "Description"])
    # Bold header row.
    ws['A3'].font = Font(bold=True)
    ws['B3'].font = Font(bold=True)
    ws['C3'].font = Font(bold=True)
    ws['D3'].font = Font(bold=True)
    ws['E3'].font = Font(bold=True)
    ws['F3'].font = Font(bold=True)
    # Center header row except for last row 'F'
    ws['A3'].alignment = Alignment(horizontal='center')
    ws['B3'].alignment = Alignment(horizontal='center')
    ws['C3'].alignment = Alignment(horizontal='center')
    ws['D3'].alignment = Alignment(horizontal='center')
    ws['E3'].alignment = Alignment(horizontal='center')
    # Resize all the columns
    ws.column_dimensions['A'].width = 30
    ws.column_dimensions['B'].width = 16
    ws.column_dimensions['C'].width = 16
    ws.column_dimensions['D'].width = 11
    ws.column_dimensions['E'].width = 18
    ws.column_dimensions['F'].width = 20
# END excelSetup()

def excelFinish():
    # Change column widths. You can't do ranges or entire columns with openpyxl, so loop.
    for row in ws[1:ws.max_row]:
        cell = row[0]  #
        cell.alignment = Alignment(horizontal='center')
    for row in ws[1:ws.max_row]:
        cell = row[1]  #
        cell.alignment = Alignment(horizontal='center')
    for row in ws[1:ws.max_row]:
        cell = row[3]  #
        cell.alignment = Alignment(horizontal='center')
# END excelFinish()

# Function to parse xml SWID Tags generated by Yocto SBOM build.
def swidParser(dir_path, output_file):
    #print(f"Parsing the SWID tags in the folder:  {dir_path} \n")

    # Create an empty dictionary to store the software identity details
    software_identity = {}

    # Counters to keep track of # of files processed and errors encountered.
    count = 0  # Counter for number of files processed.
    errCount = 0  # Counter for number of error files processed.

    # Open file to write the output
    with open(output_file, 'w') as f:
        with IncrementalBar('Processing SWID tags', max=len(os.listdir(dir_path))) as bar:
            # Iterate over files in the provided directory
            for filename in os.listdir(dir_path):
                file = os.path.join(dir_path, filename)  # Join filename with path.
                if os.path.isfile(file):  # Checking if the file is in fact a file.
                    if filename != 'cyclonedx.xml':  # If current file is NOT cyclonedx.xml (This contains all the SBOM data and isn't useful for this scripts purpose).
                        tree = ET.parse(file)  # Parse the current file xml tree, aka read in the file to the tree variable as an xml file.
                        root = tree.getroot()  # Get root node/Element of tree.

                        # Error checking for xml tree to make sure the elements exist before moving on. Can also use .findall("{*}").
                        # If the Entity element/node does not exist return control to top of loop.
                        if root.tag != '{http://standards.iso.org/iso/19770/-2/2015/schema.xsd}SoftwareIdentity':
                            # If only Software Identity does not exist ...
                            #print('ERROR: Software Identity (Root) element does no exist in this file: ' + filename + '\n')
                            errCount = errCount + 1
                            count = count + 1
                            bar.next()
                            continue

                        # Extract the name and version attributes from the SoftwareIdentity tag.
                        name = root.attrib['name']
                        version = root.attrib['version']

                        # Add the name and version to the dictionary
                        software_identity['name'] = name
                        software_identity['version'] = version

                        # Create a formatted string and write to the file
                        output_str = f"{name} - {version}\n"
                        f.write(output_str)

                        # Counter for counting number of files processed.
                        count = count+1
                        bar.next()
                    else:
                        #print("cyclonedx.xml file found and ignored:\n")
                        errCount = errCount + 1
                        count = count+1
                        bar.next()
    bar.finish()
    # Print processing information to terminal.
    print(f'''
        Total files processed: {str(count)}
        Total files with errors: {str(errCount)}
        Total completed: {str((count-errCount))}\n
        ''')
    return output_file
# END swidParser()

# Function to search the nvd database
def nvd_search(input_file):
    print('Checking CVEs ...\n')
    # Call function to set header formatting of excel spreadsheet.
    excelSetup()

    # Open the file and read list of packages and store in variable.
    with open(input_file, "r") as f:
        opkg_packages = [line.strip() for line in f.readlines()]
        
    # Initialize progress bar and set the threshold for the number of lines in the file.
    bar = IncrementalBar("Processing Packages: ", max = len(opkg_packages))

    print(f"There were {len(opkg_packages)} packages read from the input file.")
    print("NOTE: This does not mean there will be only this many in the output as there may be more than one CVE associated with each package.\n")
    #print(f"Opening and reading the file -> {input_file} \n")

    # Loop through OPKG packages and query NVD API for each
    for package in opkg_packages:
        bar.next() # Move progress bar by 1.

        # This checks to make sure the line has a hyphen surrounded by spaces in it.
        if ' - ' in package:
            package_name, package_version = package.split(" - ")
        # If there isn't a hyphen surrounded by spaces append the package name/version and error to excel spreadsheet and move on.
        else:
            ws.append([package, package_version, '', '', '', "Formatting incorrect!"])
            continue # Return control at the top of loop.
        
        # Check if noKey is True/False and sets appropriate url variable(s) and sleep timer per NVD API documentation.
        if noKey:
            # See https://nvlpubs.nist.gov/nistpubs/Legacy/IR/nistir7695.pdf for full documentation of the API. Document # NISTIR7695
            url = f"https://services.nvd.nist.gov/rest/json/cves/1.0?cpeMatchString=cpe:2.3:a:*:{package_name}:{package_version}"
            
            # Suggested pause per API documentation. 6 secs between query with no API key otherwise the NVD API will disallow you and you will get 404 errors.
            time.sleep(6)
        else:
            # See https://nvlpubs.nist.gov/nistpubs/Legacy/IR/nistir7695.pdf for full documentation of the API. Document # NISTIR7695
            url = f"https://services.nvd.nist.gov/rest/json/cves/1.0?apikey={apiKey}&cpeMatchString=cpe:2.3:a:*:{package_name}:{package_version}"
        
        # Query NVD API
        response = requests.get(url)
        # Tests if site responded.
        if response.status_code == 200: 
            # Receive json data from NVD.
            cve_items = response.json()["result"]["CVE_Items"]

            if cve_items: # Tests if there were results returned.
            # Parse jason. You can change this to add/remove data as it got the entire response from line above.
                for cve_item in cve_items:
                    #print(f'\n{package_name}-{package_version}')
                    # Store CVE-ID
                    cve_id = cve_item["cve"]["CVE_data_meta"]["ID"]
                    # Store CWE-ID. Not using this yet.
                    cwe_id = cve_item["cve"]["problemtype"]["problemtype_data"][0]["description"][0]["value"]
                    # Handle error where baseMetricV3 doesn't exist just skip it, get the rest of the info and append to excel.
                    if 'baseMetricV3' not in cve_item["impact"]:
                        # Store date published
                        published_date = cve_item["publishedDate"]
                        # Store description
                        description = cve_item["cve"]["description"]["description_data"][0]["value"]
                        # Write to file.
                        ws.append([package_name, package_version, cve_id, 'Not Provided', published_date, description])
                        continue # Return control to top of loop to next item in list.
                    # Store CVSS score
                    cvss_score = cve_item["impact"]["baseMetricV3"]["cvssV3"]["baseScore"]
                    # Store date published
                    published_date = cve_item["publishedDate"]
                    # Store description
                    description = cve_item["cve"]["description"]["description_data"][0]["value"]
                    # Write to file.
                    ws.append([package_name, package_version, cve_id, cvss_score, published_date, description])
            else:
                # Didn't find any CVEs associated with the package and version.
                ws.append([package_name, package_version, "None Found"])
        else:
            # Error reporting and write to excel.
            #print(f" Error querying NVD API for {package_name} {package_version}: {response.status_code} {response.reason}")
            # Write to file.
            ws.append([package_name, package_version, response.status_code, response.reason])
    bar.finish() # Progress finished
    return ()
# END nvd_search()



# Parse command line arguments
def getArgs(argv=None):
    parser = argparse.ArgumentParser(description="Try to look up CVE's from the National Vulnerability Database (NVD) for a file listing of packages")
    parser.add_argument('-i', '--infile', help='Input File', required=False)
    parser.add_argument('-k', '--nvdKey', help='NVD API Key', required=False)
    parser.add_argument('-o', '--outfile', help='The file to write results (needs to be writable for current user)', required=True)
    parser.add_argument('-b', '--banner', help='This will display as the top header of your excel document above the column headers. ', required=False, default='OS/Kernel/Version Unknown')
    parser.add_argument('-s', '--sbom', help='This will parse swid tags in xml format. You must give words and things and stuff', required=False)
    parser.add_argument('-f', '--infolder', help='Folder', required=False)
    parser.add_argument('-pkg', '--pkg_mgr', help='This is for the kernel/OS. Example: rpm, dpkg, opkg, etc. They are not all supported.', required=False)
    parser.add_argument('-p', '--parser', help='This will parse a package listing. Run the following to collect packages in the proper format before feeding it to this parser.', required=True)
    return parser.parse_args(argv)
# END getArgs()



### PACKAGE PARSERS ###

# OPKG Parser
def opkg_parser(input_file_path):
    
    # Run opkg list-installed > opkgList.txt to obtain the package listing and then run with this tool.
    # Run cat opkgList.txt | sed 's/[+].*$//' | sed 's/\-r.*//' | sed 's/\~r.*//' | sed '/-/!d' > newpackageTest.txt
    # or
    # nvd-cve-tool_v5.py <paramters>
    
    #print(f"Parsing and fixing packages from: {input_file_path} \n")

    # Define the regex pattern(s) to fix package file contents.
    pattern = r"-r[0-9].*$" # remove anything with -r# off the end.
    pattern2 = r"~r.*"      # remove anything with ~r off the end..
    pattern3 = r"-cip.*"    # removes all occurrences of -cip. odd the end.
    pattern4 = r'([a-zA-Z0-9-]+)-(?!.*-)(\d+\.\d+\.\d+)' # fixes kernel package output.
    pattern5 = r"\+.*"      # remove anything with a + off the end.
    pattern6 =  r"\^.*"     # remove anything with a ^ and anything after.

    # Open the file for reading and writing at the same time.
    with open(input_file_path, 'r+') as file:
        # Read the contents of the file.
        content = file.read()
        # Perform the substitution on the content.
        # re.MULTILINE/re.M flag is used with metacharacter ^ (caret) and $ (dollar). When this flag is specified,
        # the metacharacter ^ matches the pattern at beginning of the string and each newline’s beginning (\n).
        # And the metacharacter $ matches pattern at the end of the string and the end of each new line (\n)
        # NOTE: For some reason the order matters, hence 1,2,5,3,4,6.
        output_string = re.sub(pattern, '', content, flags=re.MULTILINE)            # Replace match with blank space.
        output_string = re.sub(pattern2, '', output_string, flags=re.MULTILINE)     # Replace match with blank space.
        output_string = re.sub(pattern5, '', output_string, flags=re.MULTILINE)     # Replace match with blank space.
        output_string = re.sub(pattern3, '', output_string, flags=re.MULTILINE)     # Replace match with blank space.
        output_string = re.sub(pattern4, r'\1 - \2', output_string, flags=re.MULTILINE) # Replace match with blank space.
        output_string = re.sub(pattern6, '', output_string, flags=re.MULTILINE)     # Replace match with blank space.

        # Move the file pointer to the beginning of the file.
        file.seek(0)

        with IncrementalBar("Processing Packages: ", max = len(output_string)) as bar:
            file.write(output_string)
            bar.next()

        # Write the modified content back to the file.
        #file.write(output_string)
        # Truncate the file to remove any remaining content after the new content.
        file.truncate()
    bar.finish()
    return input_file_path
# End opkg_parser()

# Package parser for debian/ubuntu
def dpkg_parser(input_file_path):
    # Run dpkg --list > dpkgList.txt
    
    #print(f"Parsing and fixing packages from: {input_file_path} \n")

    # Define the regex pattern(s) to fix package file contents.
    pattern = r'~.*'                # Removes ~ from string
    pattern2 = r'(?<!^)ubuntu'      # Removes ubuntu from the string preserving it if it starts with 'ubuntu'
    pattern3 = r'-(?![^-]*-).*$'
    pattern4 = r'\+dfsg.*'          # Removes +dfsg from string
    pattern5 = r'(?<!^)git'         # Removes git from string
    pattern6 = r'\+nmu1.*'          # Removes +nmu1 from string
    pattern7 = r'(?<!^)build'       # Removes build from string
    pattern8 = r'\d+:'
    pattern9 = r'-\w*$'
    pattern10 = r'\.dfsg.*'         # Removes dfsg from string
    pattern11 = r'(\+[^+]*$)'
    pattern12 = r'alpha.*'          # Removes alpha and everyting following
    pattern13 = r'linaro.*'         # Removes linaro and everything following
    pattern14 = r'\+bzr.*'          # Removes +nmu1 from string

    '''
    +urwcyr
    +svn
    +repack
    libtimemmgr2 - 2.0020110626+a6dda467f
    +doc
    +nmu
    -beta
    ttf-unfonts-core - 1.0.3.is.1.0.1
    ubuntu-keyring - 2010.+09.30
    '''

    # Open the file for reading and writing at the same time.
    with open(input_file_path, 'r+') as file:
        # Read the contents of the file.
        content = file.read()
        # Perform the substitution on the content.
        # re.MULTILINE/re.M flag is used with metacharacter ^ (caret) and $ (dollar). When this flag is specified,
        # the metacharacter ^ matches the pattern at beginning of the string and each newline’s beginning (\n).
        # And the metacharacter $ matches pattern at the end of the string and the end of each new line (\n)
        output_string = re.sub(pattern, '', content, flags=re.MULTILINE)
        output_string = re.sub(pattern2, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern3, '', output_string, flags=re.MULTILINE)
        # capture the portion of the string that starts with g++ and includes everything up to the first two + characters, 
        # and then we use that captured group \1 as the replacement string. This effectively removes the + and everything 
        # after it while preserving the part we captured.
        output_string = re.sub(r'(g\+\+.*?\+.*)\+.*', r'\1', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern4, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern5, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern6, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern7, '', output_string, flags=re.MULTILINE) 
        output_string = re.sub(pattern8, '', output_string, flags=re.MULTILINE) 
        output_string = re.sub(pattern9, '', output_string, flags=re.MULTILINE) 
        output_string = re.sub(pattern10, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern12, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern13, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(pattern14, '', output_string, flags=re.MULTILINE)
        output_string = re.sub(r'(\d+)\+(\d+)', r'\1\2', output_string, flags=re.MULTILINE) 
        output_string = re.sub(r'([a-zA-Z0-9-]+)-([0-9.]+)', r'\1 - \2', output_string, flags=re.MULTILINE)

        # Move the file pointer to the beginning of the file.
        file.seek(0)

#        with IncrementalBar("Processing Packages: ", max = len(output_string)) as bar:
        file.write(output_string) # Write the modified content back to the file.
#            bar.next()

        file.truncate() # Truncate the file to remove any remaining content after the new content.
 #   bar.finish()
    return input_file_path
# END dpkg_parser()

# RPM Parser
# Run, rpm -qa --queryformat "%{NAME} - %{VERSION}\n" > rpmList.txt
def rpm_parser(input_file_path):
    parsed_data = []
    with open(input_file_path, 'r') as f:
        lines = f.readlines()
        for line in lines:
            match = re.match(r'^(\S+)-(\d[\S]*?)-(\S+)\.(\S+)$', line.strip())
            if match:
                name, version, release, architecture = match.groups()
                parsed_data.append({
                    'name': name,
                    'version': f'{version}-{release}',
                    'architecture': architecture
                })
    return parsed_data
# END rpm_parser()

# END PKG PARSERS








# BEGIN

print ("""
    .----.   @   @
   / .-"-.`.  \v/
   | | '\ \ \_/ )
 ,-\ `-.' /.'  /
'---`----'----'
""")
delay_print('Snail CVE Lookup Tool ... ¯\_(ツ)_/¯')
print ('\n')

# Call getArgs to process command line arguments.
args = getArgs()
# Check if both an and input file and input folder was chosen and if so, print message and exit.
if args.infolder and args.infile:
    print("ERROR: You provided both and input folder and and input file. Please only use one or the other. The folder option is used with sbom parsing only.\n")
    exit()
# Check if an and input file or input folder was chosen and if not, print message and exit.
if not args.infolder and not args.infile:
    print("ERROR: Input file or input folder were not provided. You have to chose either and input file or and input folder to do something.\n")
    exit()

# Start the timer
start_time = datetime.datetime.now()

# If the input file was provided then set the variable from argument provided.
if args.infile:
    inputFile = os.path.abspath(args.infile)

# Set the output file to the variable from argument provided.
outputFile = os.path.abspath(args.outfile)

# Reads nvdKey argument and sets noKey bool.
if args.nvdKey:
    apiKey = args.nvdKey
    noKey = False
else:
    print('No NVD API key supplied. The queries will be restricted to 1 every 6 seconds.'
    'This is probably going to be very slow for you depending on how many packages there are.\n\n'
    'You should get an API key from NVD: https://nvd.nist.gov/developers/request-an-api-key \n')
    noKey = True

# Variable for printing this in the excel document on the top if provided.
if args.banner:
    bannerInfo = args.banner

# Run appropriate parser
if args.parser:
    delay_print("Running file parser only!")
    print('\n')
    pkgMgr = args.parser
    if pkgMgr == 'opkg':
        inputFile = os.path.abspath(args.infile)
        opkg_parser(inputFile)
        exit()
    elif pkgMgr == 'dpkg':
        inputFile = os.path.abspath(args.infile)
        dpkg_parser(inputFile)
        exit()
    elif pkgMgr == 'rpm':
        inputFile = os.path.abspath(args.infile)
        rpm_parser(inputFile)
        exit() 
    # TODO: Add other pkgmgr functionality.
    else:
        print(f"I don't know how to parse {pkgMgr} packages yet.")

# If NO input folder was provided.
if not args.infolder:
    # Checks if file exists and if it doesn't print message and exit.
    if not os.path.exists(args.infile):
        print(f"ERROR: Input file does not exit {args.infile}\n")
        exit()
    # If there's no input folder the input file should be chosen.
    else:
        if not os.path.exists(args.infile):
            print(f"ERROR: Input file does not exit {args.infile}\n")
            exit()
        # If all above good, sets inputFile to absolute path of infile. Arg parser takes care of making the output file mandatory.
        else:
            # Parse input file into the correct format and return the new file and store in variable.
            parsed_input_file = opkg_parser(inputFile)
            # Test internet connection.
            if not connect():
                print('You have no internet! Please connect to the internet for the CVE lookup to work.\n')
                exit()
            # Call NVD search function
            nvd_search(parsed_input_file)
# If input folder was provided.
else:
    # Check if the folder exists and if it doesn't print message and exit.
    if not os.path.isdir(args.infolder):
        print(f"ERROR: The input folder provided {args.infolder}\n")
        exit()
    # Set the variable as the given folder path.
    inputFolder = args.infolder
    # sets outfile argument
    outputFile = os.path.abspath(args.outfile)
    if args.sbom:
        inputFile = swidParser(inputFolder, outputFile)
        inputFile = opkg_parser(inputFile)
        # Test internet connection.
        if not connect():
            print('You have no internet! Please connect to the internet for this script to work.\n')
            exit()
        # Call NVD search function
        nvd_search(inputFile)

# Format completed spreadsheet before writing to file.
excelFinish()

outputFile = args.outfile
outputFile = os.path.splitext(outputFile)[0]+'.xlsx'  # Changes .txt to .xlsx
# Save Excel spreadsheet
wb.save(outputFile)
outputFile = os.path.abspath(outputFile)
print(f"File written to : {outputFile}")

# Stop the timer
end_time = datetime.datetime.now()
# Calculate the elapsed time
elapsed_time = end_time - start_time
# Convert the elapsed time to minutes and seconds
minutes, seconds = divmod(elapsed_time.total_seconds(), 60)
# Print the elapsed time
print("Elapsed time: {:02d}:{:02d}".format(int(minutes), int(seconds)))